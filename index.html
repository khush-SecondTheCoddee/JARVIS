<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>JARVIS MK-100 AR</title>
    
    <!-- PWA -->
    <link rel="manifest" href="manifest.json">
    <meta name="theme-color" content="#00f2ff">
    
    <!-- LIBRARIES -->
    <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script> <!-- 3D Engine -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
    <script src="https://unpkg.com/compromise"></script> <!-- NLP -->
    
    <!-- FONTS -->
    <link href="https://fonts.googleapis.com/css2?family=Rajdhani:wght@500;700&family=Share+Tech+Mono&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <style>
        :root { --primary: #00f2ff; --secondary: #ff0055; --bg: #000; }
        body { margin: 0; overflow: hidden; background: var(--bg); font-family: 'Rajdhani', sans-serif; user-select: none; }

        /* AR LAYERS */
        #cam-feed { position: fixed; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: -2; }
        
        /* The A-Frame Scene sits transparently on top */
        #ar-scene { position: fixed; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; }

        /* UI OVERLAY */
        #ui-layer { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 10; pointer-events: none; display: flex; flex-direction: column; justify-content: space-between; padding: 20px; box-sizing: border-box; }
        
        .hud-header { display: flex; gap: 10px; }
        .badge { background: rgba(0, 20, 30, 0.8); border: 1px solid var(--primary); padding: 5px 15px; color: var(--primary); font-family: 'Share Tech Mono'; font-size: 12px; backdrop-filter: blur(5px); clip-path: polygon(10px 0, 100% 0, 100% 100%, 0 100%, 0 10px); }

        #hand-cursor {
            position: absolute; width: 40px; height: 40px; 
            border: 2px dashed var(--primary); border-radius: 50%;
            transform: translate(-50%, -50%); transition: width 0.1s;
            pointer-events: none; display: none; /* Hidden until hand detected */
            z-index: 20; box-shadow: 0 0 20px var(--primary);
        }
        #hand-cursor.grabbing { border-color: var(--secondary); background: rgba(255, 0, 85, 0.2); width: 20px; height: 20px; }

        .controls { pointer-events: auto; display: flex; gap: 10px; overflow-x: auto; padding-bottom: 20px; justify-content: center; }
        .btn { background: rgba(0,0,0,0.8); border: 1px solid var(--primary); color: var(--primary); padding: 10px 20px; font-weight: bold; cursor: pointer; white-space: nowrap; clip-path: polygon(10px 0, 100% 0, 100% 70%, 90% 100%, 0 100%, 0 30%); }
        .btn:active { background: var(--primary); color: #000; }

        #console { font-family: 'Share Tech Mono'; color: #fff; text-shadow: 0 0 5px var(--primary); text-align: center; margin-bottom: 10px; }

        /* ANIMATIONS */
        @keyframes scan { 0% { top: 0%; opacity: 0; } 50% { opacity: 1; } 100% { top: 100%; opacity: 0; } }
        .scanner-line { position: absolute; width: 100%; height: 2px; background: var(--primary); animation: scan 2s infinite; opacity: 0.5; z-index: 0; }
    </style>
</head>
<body>

    <!-- 1. VIDEO BACKGROUND (The Real World) -->
    <video id="cam-feed" autoplay muted playsinline></video>
    <div class="scanner-line"></div>

    <!-- 2. A-FRAME SCENE (The Holograms) -->
    <a-scene id="ar-scene" embedded vr-mode-ui="enabled: false">
        <a-assets>
            <!-- PRE-LOADED MODELS (Hosted Free CDNs) -->
            <a-asset-item id="model-helmet" src="https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/SciFiHelmet/glTF/SciFiHelmet.gltf"></a-asset-item>
            <a-asset-item id="model-drone" src="https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/CesiumMilkTruck/glTF/CesiumMilkTruck.gltf"></a-asset-item>
            <a-asset-item id="model-brain" src="https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/BrainStem/glTF/BrainStem.gltf"></a-asset-item>
        </a-assets>

        <!-- Camera Rig -->
        <a-entity id="rig" position="0 1.6 0">
            <a-entity id="main-cam" camera look-controls="enabled: false" wasd-controls="enabled: false"></a-entity>
        </a-entity>

        <!-- Lighting -->
        <a-light type="ambient" color="#ffffff" intensity="1"></a-light>
        <a-light type="point" position="2 4 -3" intensity="2" color="#00f2ff"></a-light>

        <!-- Anchor Point for Objects -->
        <a-entity id="anchor" position="0 1.6 -3"></a-entity>
    </a-scene>

    <!-- 3. HUD INTERFACE -->
    <div id="ui-layer">
        <div class="hud-header">
            <div class="badge">MK-100 ARCHITECT</div>
            <div class="badge" id="hand-status">HANDS: SCANNING</div>
        </div>

        <!-- The 2D Cursor tracking your hand -->
        <div id="hand-cursor"></div>

        <div>
            <div id="console">>> INITIALIZE SYSTEM TO BEGIN</div>
            <div class="controls">
                <button class="btn" onclick="sys.init()">INIT SYSTEM</button>
                <button class="btn" onclick="ar.spawn('helmet')">HELMET</button>
                <button class="btn" onclick="ar.spawn('drone')">VEHICLE</button>
                <button class="btn" onclick="ar.spawn('brain')">BIO-SCAN</button>
                <button class="btn" onclick="ar.clear()">CLEAR</button>
            </div>
        </div>
    </div>

    <script>
        // --- CONFIG ---
        const ui = {
            console: document.getElementById('console'),
            handStatus: document.getElementById('hand-status'),
            cursor: document.getElementById('hand-cursor'),
            anchor: document.getElementById('anchor'),
            video: document.getElementById('cam-feed')
        };

        let activeObject = null;
        let isGrabbing = false;

        // --- 1. SYSTEM CORE ---
        const sys = {
            init: async () => {
                ui.console.innerText = ">> CALIBRATING OPTICAL SENSORS...";
                await cam.start();
                voice.speak("Architect mode engaged. Hand tracking online.");
                ui.console.innerText = ">> READY. USE VOICE OR BUTTONS.";
                voice.listen();
            }
        };

        // --- 2. AR & HOLOGRAM ENGINE ---
        const ar = {
            spawn: (type) => {
                // Clear previous
                ui.anchor.innerHTML = '';
                
                const el = document.createElement('a-entity');
                
                // Set Model
                if(type === 'helmet') {
                    el.setAttribute('gltf-model', '#model-helmet');
                    el.setAttribute('scale', '0.5 0.5 0.5');
                } else if(type === 'drone') {
                    el.setAttribute('gltf-model', '#model-drone');
                    el.setAttribute('scale', '0.5 0.5 0.5');
                } else if(type === 'brain') {
                    el.setAttribute('gltf-model', '#model-brain');
                    el.setAttribute('scale', '1 1 1');
                } else if(type === 'cube') {
                    el.setAttribute('geometry', 'primitive: box');
                    el.setAttribute('material', 'color: #00f2ff; opacity: 0.7; transparent: true; wireframe: true');
                }

                // Default Animation (Float)
                el.setAttribute('animation', 'property: rotation; to: 0 360 0; loop: true; dur: 10000; easing: linear');
                
                ui.anchor.appendChild(el);
                activeObject = el;
                voice.speak(`Constructing ${type} model.`);
                ui.console.innerText = `>> SPAWNED: ${type.toUpperCase()}`;
            },

            clear: () => {
                ui.anchor.innerHTML = '';
                activeObject = null;
                voice.speak("Workspace cleared.");
            },

            modify: (attr, value) => {
                if(!activeObject) return;
                
                if(attr === 'color') {
                    // Only works on primitives, for models we'd need to traverse mesh
                    activeObject.setAttribute('material', `color: ${value}`);
                }
                if(attr === 'scale') {
                    activeObject.setAttribute('scale', `${value} ${value} ${value}`);
                }
                if(attr === 'wireframe') {
                    // Simple material override hack for primitives
                    activeObject.setAttribute('material', 'wireframe: true; color: #00f2ff');
                }
            }
        };

        // --- 3. HAND TRACKING & TELEKINESIS ---
        const cam = {
            start: async () => {
                const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
                hands.setOptions({maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.6});
                hands.onResults(cam.onHand);

                const camera = new Camera(ui.video, {
                    onFrame: async () => { await hands.send({image: ui.video}); },
                    width: 1280, height: 720
                });
                camera.start();
            },

            onHand: (results) => {
                if (results.multiHandLandmarks.length > 0) {
                    const lm = results.multiHandLandmarks[0];
                    ui.handStatus.innerText = "HANDS: LOCKED";
                    ui.handStatus.style.borderColor = "#00f2ff";
                    
                    // 1. Update 2D Cursor
                    // MediaPipe coords are normalized (0-1). Map to screen.
                    const x = (1 - lm[9].x) * window.innerWidth; // Mirror effect
                    const y = lm[9].y * window.innerHeight;
                    
                    ui.cursor.style.display = 'block';
                    ui.cursor.style.left = `${x}px`;
                    ui.cursor.style.top = `${y}px`;

                    // 2. Pinch Detection (Thumb 4 & Index 8)
                    const pinchDist = Math.hypot(lm[8].x - lm[4].x, lm[8].y - lm[4].y);
                    
                    if(pinchDist < 0.05) {
                        // GRABBING
                        if(!isGrabbing) {
                            isGrabbing = true;
                            ui.cursor.classList.add('grabbing');
                        }

                        // TELEKINESIS LOGIC
                        if(activeObject) {
                            // Map 2D hand to 3D A-Frame Coordinates
                            // Screen Center is (0,0,0) in A-Frame usually
                            // Map x(0 to 1) -> -2 to 2
                            // Map y(0 to 1) -> 1.5 to -1.5
                            const moveX = (0.5 - lm[9].x) * 6; // Multiplier for sensitivity
                            const moveY = (0.5 - lm[9].y) * 4;
                            
                            activeObject.setAttribute('position', `${moveX} ${moveY} 0`);
                        }

                    } else {
                        // RELEASE
                        if(isGrabbing) {
                            isGrabbing = false;
                            ui.cursor.classList.remove('grabbing');
                        }
                    }

                } else {
                    ui.handStatus.innerText = "HANDS: LOST";
                    ui.handStatus.style.borderColor = "red";
                    ui.cursor.style.display = 'none';
                }
            }
        };

        // --- 4. VOICE CORE ---
        const voice = {
            synth: window.speechSynthesis,
            recognition: new (window.SpeechRecognition || window.webkitSpeechRecognition)(),
            
            listen: () => {
                voice.recognition.lang = 'en-US';
                voice.recognition.continuous = true;
                voice.recognition.onresult = (e) => {
                    const text = e.results[e.results.length-1][0].transcript.toLowerCase();
                    ui.console.innerText = `CMD: ${text}`;
                    voice.process(text);
                };
                voice.recognition.start();
            },

            speak: (text) => {
                const utter = new SpeechSynthesisUtterance(text);
                utter.rate = 1.1;
                voice.synth.speak(utter);
            },

            process: (cmd) => {
                // SPAWN LOGIC
                if(cmd.includes('helmet')) ar.spawn('helmet');
                else if(cmd.includes('vehicle') || cmd.includes('truck') || cmd.includes('drone')) ar.spawn('drone');
                else if(cmd.includes('brain') || cmd.includes('scan')) ar.spawn('brain');
                else if(cmd.includes('box') || cmd.includes('cube')) ar.spawn('cube');
                
                // MODIFICATION
                else if(cmd.includes('bigger') || cmd.includes('enlarge')) ar.modify('scale', 1.5);
                else if(cmd.includes('smaller') || cmd.includes('shrink')) ar.modify('scale', 0.2);
                else if(cmd.includes('wireframe') || cmd.includes('x-ray')) ar.modify('wireframe');
                
                // CLEANUP
                else if(cmd.includes('clear') || cmd.includes('remove')) ar.clear();
                
                // SYSTEM
                else if(cmd.includes('shutdown')) {
                     voice.speak("Systems offline."); 
                     document.body.style.display = 'none'; 
                }
            }
    </script>
</body>
</html>
